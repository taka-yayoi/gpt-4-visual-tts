{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60140a45-a661-4f2d-b360-f7ee60136696",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "[Processing and narrating a video with GPT's visual capabilities and the TTS API \\| OpenAI Cookbook](https://cookbook.openai.com/examples/gpt_with_vision_for_video_understanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f6cf131-8e98-4691-a8db-8fcef721bcf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install opencv-python\n",
    "%pip install -U openai\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf072fa7-ae5b-4c5a-ba4b-0a5d78e67f92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "このノートブックは、ビデオを使用してGPTの視覚的な機能を示します。GPT-4oはビデオを直接入力として受け取りませんが、ビジョンと128Kコンテキストウィンドウを使用して、ビデオ全体の静止フレームを一度に説明することができます。2つの例を通して説明します：\n",
    "\n",
    "1. GPT-4oを使用してビデオの説明を取得する\n",
    "1. GPT-oとTTS APIを使用してビデオのナレーションを生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "393a178f-67fe-4339-9e4b-60ac81afe570",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image, Audio\n",
    "\n",
    "import cv2  # ビデオを読み取るためにOpenCVを使用しています。インストールするには !pip install opencv-python\n",
    "import base64\n",
    "import time\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import requests\n",
    "\n",
    "client = OpenAI(api_key=dbutils.secrets.get(\"demo-token-takaaki.yayoi\", \"openai_api_key\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d4c25f8-cef9-4652-9f8e-d43abb92d063",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = dbutils.secrets.get(\"demo-token-takaaki.yayoi\", \"openai_api_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03897a5e-d98f-45ea-94cc-b2e107ec07fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. GPTの視覚的な機能を使用してビデオの説明を取得する\n",
    "\n",
    "まず、OpenCVを使用して鳥が写っている動画からフレームを抽出します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbfa1355-a734-41e6-81ed-9622df4c1326",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"data/birds.MP4\")\n",
    "\n",
    "base64Frames = []\n",
    "while video.isOpened():\n",
    "    success, frame = video.read()\n",
    "    if not success:\n",
    "        break\n",
    "    _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "    base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "\n",
    "video.release()\n",
    "print(len(base64Frames), \"frames read.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04f2de5a-34a8-47d4-aea9-b7831550dfcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "フレームが正しく読み込まれたことを確認するために表示します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1c9c13d-044b-4956-a561-b6eb09016b8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display_handle = display(None, display_id=True)\n",
    "\n",
    "for img in base64Frames:\n",
    "    display_handle.update(Image(data=base64.b64decode(img.encode(\"utf-8\"))))\n",
    "    time.sleep(0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9285acc3-e134-4e48-9c98-53144690ac63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "ビデオフレームを取得したら、プロンプトを作成してGPTにリクエストを送信します（GPTが状況を理解するためにすべてのフレームを送信する必要はありません）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "691b75e1-392e-4237-af9b-842002a05dd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PROMPT_MESSAGES = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            \"これはアップロードしたいビデオのフレームです。ビデオと一緒にアップロードできる魅力的な説明を生成してください。\",\n",
    "            *map(lambda x: {\"image\": x, \"resize\": 768}, base64Frames[0::50]),\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "params = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": PROMPT_MESSAGES,\n",
    "    \"max_tokens\": 200,\n",
    "}\n",
    "\n",
    "result = client.chat.completions.create(**params)\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53c9ede0-83a3-46e4-ba10-0c2c99bbc569",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. GPT-4とTTS(Text To Speech) APIを使用したビデオのナレーション生成\n",
    "\n",
    "このビデオのナレーションをデイビッド・アッテンボロー風に作成しましょう。同じビデオフレームを使用して、GPTに短いスクリプトを作成させます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf0bce16-fbbc-4baf-ad50-c3ad20f5a17d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PROMPT_MESSAGES = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            \"これらはビデオのフレームです。デイビッド・アッテンボローのスタイルで短いナレーションスクリプトを作成してください。ナレーションのみを含めてください。\",\n",
    "            *map(lambda x: {\"image\": x, \"resize\": 768}, base64Frames[0::60]),\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "params = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": PROMPT_MESSAGES,\n",
    "    \"max_tokens\": 500,\n",
    "}\n",
    "\n",
    "result = client.chat.completions.create(**params)\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3bae74ea-94e4-44f9-9d02-f0aeb6726930",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "次に、スクリプトをTTS APIに渡して、ナレーションのmp3を生成します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15bf1f28-91b6-4db3-b15e-83ed140c7487",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    \"https://api.openai.com/v1/audio/speech\",\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\",\n",
    "    },\n",
    "    json={\n",
    "        \"model\": \"tts-1-1106\",\n",
    "        \"input\": result.choices[0].message.content,\n",
    "        \"voice\": \"onyx\",\n",
    "    },\n",
    ")\n",
    "\n",
    "audio = b\"\"\n",
    "for chunk in response.iter_content(chunk_size=1024 * 1024):\n",
    "    audio += chunk\n",
    "Audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8392cfc2-306d-4afa-8bb0-1b949895ff74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with open('data/birds_narration.wav', 'wb') as f:\n",
    "  f.write(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4456d5ee-c15d-4ad0-a6b2-ee44ba352c91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "GPT-4 Video Frame Analysis and Narration",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
